{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    break","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-29T08:16:55.301579Z","iopub.execute_input":"2022-08-29T08:16:55.302515Z","iopub.status.idle":"2022-08-29T08:16:55.337988Z","shell.execute_reply.started":"2022-08-29T08:16:55.301981Z","shell.execute_reply":"2022-08-29T08:16:55.336724Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# needed libraries\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.measure import label, regionprops, find_contours\nimport tensorflow as tf\nimport keras \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, UpSampling2D, Concatenate, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:16:55.340461Z","iopub.execute_input":"2022-08-29T08:16:55.340999Z","iopub.status.idle":"2022-08-29T08:17:03.078611Z","shell.execute_reply.started":"2022-08-29T08:16:55.340956Z","shell.execute_reply":"2022-08-29T08:17:03.077376Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/airbus-ship-detection/train_ship_segmentations_v2.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:17:03.080255Z","iopub.execute_input":"2022-08-29T08:17:03.080960Z","iopub.status.idle":"2022-08-29T08:17:04.282586Z","shell.execute_reply.started":"2022-08-29T08:17:03.080916Z","shell.execute_reply":"2022-08-29T08:17:04.281249Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:17:04.286440Z","iopub.execute_input":"2022-08-29T08:17:04.286871Z","iopub.status.idle":"2022-08-29T08:17:04.313037Z","shell.execute_reply.started":"2022-08-29T08:17:04.286831Z","shell.execute_reply":"2022-08-29T08:17:04.311809Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# decode pixels to take mask\ndef find_mask(encoded_pixels, size):\n    my_img = []\n\n    for i in range(0, len(encoded_pixels), 2):\n        steps = encoded_pixels[i+1]\n        start = encoded_pixels[i]\n        start -= 1\n\n        pos_of_pixels = [start+j for j in range(steps)]\n        my_img.extend(pos_of_pixels)\n\n    mask_img = np.zeros((size**2), dtype=np.uint8)\n    mask_img[my_img] = 1\n    mask = np.reshape(mask_img, (size,size)).T\n\n    return mask\n\n\ndef rle_encode(mask, zeros=1e-3):\n    mask = mask.T.flatten()\n\n    mask = np.argwhere(mask > zeros)\n\n    if mask.size > 0:\n        final_ans = []\n        num = 1\n        first = mask[0]\n        for i in range(len(mask)):\n            if i+1 != len(mask):\n                if mask[i]+1 == mask[i+1]:\n                    num += 1\n                else:\n                    final_ans.extend([first[0],num])\n                    first = mask[i+1]\n                    num = 1\n        final_ans = [str(i) for i in final_ans]\n\n        return ' '.join(final_ans)\n    else:\n        return np.nan","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:17:04.315369Z","iopub.execute_input":"2022-08-29T08:17:04.315809Z","iopub.status.idle":"2022-08-29T08:17:04.329434Z","shell.execute_reply.started":"2022-08-29T08:17:04.315772Z","shell.execute_reply":"2022-08-29T08:17:04.327768Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)\nnp.random.shuffle(train.values)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:17:04.331605Z","iopub.execute_input":"2022-08-29T08:17:04.332531Z","iopub.status.idle":"2022-08-29T08:17:04.566654Z","shell.execute_reply.started":"2022-08-29T08:17:04.332491Z","shell.execute_reply":"2022-08-29T08:17:04.565183Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_without_ship = train[train['EncodedPixels'].isna()]\ntrain_without_ship.index = [i for i in range(len(train_without_ship))]\ntrain_with_ship = train[train['EncodedPixels'].notna()].groupby('ImageId')['EncodedPixels'].apply(lambda x: ' '.join(x)).to_frame()\ntrain_with_ship = train_with_ship.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:17:04.571079Z","iopub.execute_input":"2022-08-29T08:17:04.571463Z","iopub.status.idle":"2022-08-29T08:17:05.498609Z","shell.execute_reply.started":"2022-08-29T08:17:04.571437Z","shell.execute_reply":"2022-08-29T08:17:05.497373Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 4000 with shape (256,256)\nn = 8000\n    \n# take arrays of images and coordinates for those imgs\nimgs_to_classification = []\nimgs_to_segmentation = []\nmask_to_segmentation = []\ny = []\n\n\nfor i in range(n):\n    try:\n        # read image resize it and normalize\n        img = cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_with_ship['ImageId'][i])\n        img = cv.GaussianBlur(img, (3,3), cv.BORDER_DEFAULT)\n        img = cv.resize(img, (160,160))\n#         img = img / 255\n        img = img.astype(np.uint8)\n\n        # decode pixels and take mask\n        encoded_pixels = [int(k) for k in train_with_ship['EncodedPixels'][i].split()]\n        mask = find_mask(encoded_pixels, 768)\n        mask = cv.resize(mask, (160,160))\n        \n        imgs_to_segmentation.append(img)\n        mask_to_segmentation.append(mask)\n\n        # take 50% of images with ships and 50% without ships\n        if i % 2 == 0:\n            imgs_to_classification.append(img)\n            y.append(np.array([1,0]))\n        else:\n            img = cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_without_ship['ImageId'][i])\n            img = cv.GaussianBlur(img, (3,3), cv.BORDER_DEFAULT)\n            img = cv.resize(img, (160,160))\n#             img = img / 255\n            img = img.astype(np.uint8)\n            imgs_to_classification.append(img)\n            y.append(np.array([0,1]))\n\n    except:\n#         print('Corrupted Img')\n        pass\n\n# change dtypes of our input and output data\nimgs_to_classification = np.array(imgs_to_classification, dtype=np.uint8)\ny = np.array(y, dtype=np.uint8)\nimgs_to_segmentation = np.array(imgs_to_segmentation, dtype=np.float16)\nmask_to_segmentation = np.array(mask_to_segmentation, dtype=np.float16)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:17:05.500233Z","iopub.execute_input":"2022-08-29T08:17:05.501061Z","iopub.status.idle":"2022-08-29T08:22:04.308480Z","shell.execute_reply.started":"2022-08-29T08:17:05.501018Z","shell.execute_reply":"2022-08-29T08:22:04.307079Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(imgs_to_classification.shape, imgs_to_segmentation.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:22:04.310455Z","iopub.execute_input":"2022-08-29T08:22:04.310838Z","iopub.status.idle":"2022-08-29T08:22:04.322311Z","shell.execute_reply.started":"2022-08-29T08:22:04.310797Z","shell.execute_reply":"2022-08-29T08:22:04.320669Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras import layers\n\n\n# Segmentation Model\ndef get_model(img_size):\n    inputs = keras.Input(shape=img_size + (3,))\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(1, 1, activation='sigmoid', padding=\"same\")(x)\n\n    # Define the model\n    model = keras.Model(inputs, outputs)\n    return model\n\n\n# # Free up RAM in case the model definition cells were run multiple times\n# keras.backend.clear_session()\n\n# Build model\n# with tpu_strategy.scope():\nmodel = get_model((160,160))\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:22:04.329610Z","iopub.execute_input":"2022-08-29T08:22:04.330505Z","iopub.status.idle":"2022-08-29T08:22:08.501743Z","shell.execute_reply.started":"2022-08-29T08:22:04.330466Z","shell.execute_reply":"2022-08-29T08:22:08.500168Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\ncnn3 = Sequential()\ncnn3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(160,160,3)))\ncnn3.add(MaxPooling2D((2, 2)))\ncnn3.add(Dropout(0.25))\n\ncnn3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\ncnn3.add(MaxPooling2D(pool_size=(2, 2)))\ncnn3.add(Dropout(0.25))\n\ncnn3.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\ncnn3.add(Dropout(0.4))\n\ncnn3.add(Flatten())\n\ncnn3.add(Dense(128, activation='relu'))\ncnn3.add(Dropout(0.3))\ncnn3.add(Dense(2, activation='sigmoid'))\n\ncnn3.compile(loss='binary_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:22:08.503709Z","iopub.execute_input":"2022-08-29T08:22:08.504242Z","iopub.status.idle":"2022-08-29T08:22:08.597812Z","shell.execute_reply.started":"2022-08-29T08:22:08.504179Z","shell.execute_reply":"2022-08-29T08:22:08.596490Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# def dice_coef(y_true, y_pred, smooth=1):\n#     intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n#     union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n#     dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n\n#     return dice\n\n\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred))\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:22:08.599571Z","iopub.execute_input":"2022-08-29T08:22:08.600036Z","iopub.status.idle":"2022-08-29T08:22:08.610425Z","shell.execute_reply.started":"2022-08-29T08:22:08.599980Z","shell.execute_reply":"2022-08-29T08:22:08.607780Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_segm_train, X_segm_valid, y_segm_train, y_segm_valid = train_test_split(imgs_to_segmentation, mask_to_segmentation.reshape(-1,160,160,1), test_size=0.1, random_state=42)\n\nX_class_train, X_class_valid, y_class_train, y_class_valid = train_test_split(imgs_to_classification, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:22:08.612742Z","iopub.execute_input":"2022-08-29T08:22:08.613703Z","iopub.status.idle":"2022-08-29T08:22:09.409375Z","shell.execute_reply.started":"2022-08-29T08:22:08.613634Z","shell.execute_reply":"2022-08-29T08:22:09.408056Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"cnn3.fit(X_class_train, y_class_train, epochs=30, batch_size=32, validation_data=(X_class_valid, y_class_valid))","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:22:09.411321Z","iopub.execute_input":"2022-08-29T08:22:09.412576Z","iopub.status.idle":"2022-08-29T08:24:33.294947Z","shell.execute_reply.started":"2022-08-29T08:22:09.412537Z","shell.execute_reply":"2022-08-29T08:24:33.293412Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"del X_class_train\ndel y_class_train\ndel X_class_valid\ndel y_class_valid","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:24:33.301850Z","iopub.execute_input":"2022-08-29T08:24:33.302176Z","iopub.status.idle":"2022-08-29T08:24:33.310932Z","shell.execute_reply.started":"2022-08-29T08:24:33.302148Z","shell.execute_reply":"2022-08-29T08:24:33.309557Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.utils import Sequence\n# import numpy as np   \n\n# class DataGenerator(Sequence):\n#     def __init__(self, x_set, y_set, batch_size):\n#         self.x, self.y = x_set, y_set\n#         self.batch_size = batch_size\n\n#     def __len__(self):\n#         return int(np.ceil(len(self.x) / float(self.batch_size)))\n\n#     def __getitem__(self, idx):\n#         batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n#         batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n#         return batch_x, batch_y\n\n# train_gen = DataGenerator(X_segm_train, y_segm_train, 32)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:24:33.312855Z","iopub.execute_input":"2022-08-29T08:24:33.313756Z","iopub.status.idle":"2022-08-29T08:24:33.325501Z","shell.execute_reply.started":"2022-08-29T08:24:33.313704Z","shell.execute_reply":"2022-08-29T08:24:33.323661Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001), loss=[dice_loss], metrics=[dice_coef])\nmodel.fit(X_segm_train, y_segm_train, batch_size=32, epochs=100, validation_data=(X_segm_valid, y_segm_valid))","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:24:33.327697Z","iopub.execute_input":"2022-08-29T08:24:33.328269Z","iopub.status.idle":"2022-08-29T09:20:13.103962Z","shell.execute_reply.started":"2022-08-29T08:24:33.328226Z","shell.execute_reply":"2022-08-29T09:20:13.102432Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# imgs = np.array([cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_with_ship.loc[3003]['ImageId']),\\\n#                 cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_with_ship.loc[2000]['ImageId']),\\\n#                 cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_without_ship.loc[788]['ImageId']),\\\n#                 cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_with_ship.loc[555]['ImageId']),\\\n#                 cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_without_ship.loc[555]['ImageId']),\\\n#                 cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_without_ship.loc[732]['ImageId'])])\n\n# imgs = np.array([cv.resize(i, (256,256)) for i in imgs])\n# print(imgs.shape)\n\n\n# final_results = []\n# i = 0\n# for predicted in model.predict(imgs):\n#     if predicted[0] == 1:\n#         final_results.append([i, model.predict(imgs[i].reshape(1, 256, 256, 3))])\n        \n#     i += 1\n\n\nind = 9694\nimg = cv.imread('/kaggle/input/airbus-ship-detection/train_v2/'+train_with_ship.loc[ind]['ImageId'])\nimg = cv.resize(img, (256,256))\nmask = find_mask([int(i) for i in train_with_ship.loc[ind]['EncodedPixels'].split()], 768)\n\nfig = plt.figure(figsize=(16,9))\n\nfig.add_subplot(1,3,1)\nplt.imshow(img)\nfig.add_subplot(1,3,2)\nplt.imshow(mask)\nfig.add_subplot(1,3,3)\nplt.imshow(model.predict(img.reshape(1,256,256,3)).reshape(256,256,1))","metadata":{"execution":{"iopub.status.busy":"2022-08-29T09:20:13.116243Z","iopub.execute_input":"2022-08-29T09:20:13.116595Z","iopub.status.idle":"2022-08-29T09:20:15.569364Z","shell.execute_reply.started":"2022-08-29T09:20:13.116567Z","shell.execute_reply":"2022-08-29T09:20:15.567377Z"},"trusted":true},"execution_count":18,"outputs":[]}]}